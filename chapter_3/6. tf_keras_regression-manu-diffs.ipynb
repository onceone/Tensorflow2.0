{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.1\n",
      "numpy 1.16.5\n",
      "pandas 0.25.2\n",
      "sklearn 0.21.3\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# 房价预测\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "# 划分样本\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all,x_test,y_train_all,y_test = train_test_split(housing.data,housing.target,random_state=7)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_train_all,y_train_all,random_state=11)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# metric 的使用\n",
    "\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5.],[2.]))\n",
    "print(metric([0.],[1.]))\n",
    "print(metric.result())\n",
    "\n",
    "metric.reset_states() # 不累加数据\n",
    "metric([1.],[3.])\n",
    "print(metric.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0 train mse: 1.3929005\t valid mse: 1.4782649324813137 0 train mse: 1.4565784 0 train mse: 1.4310099\n",
      "Epoch 1 train mse: 1.2999024\t valid mse: 1.488663170622757\n",
      "Epoch 2 train mse: 1.3761767\t valid mse: 1.6291672277288813\n",
      "Epoch 3 train mse: 1.2543038\t valid mse: 1.4058062990249831\n",
      "Epoch 4 train mse: 1.2327455\t valid mse: 1.3966837797020484\n",
      "Epoch 5 train mse: 1.2839633\t valid mse: 1.3921975667621207e: 1.3302975 5 train mse: 1.326815\n",
      "Epoch 6 train mse: 1.2427859\t valid mse: 1.39011884046943531.243005\n",
      "Epoch 7 train mse: 1.2365131\t valid mse: 1.388816978692682\n",
      "Epoch 8 train mse: 1.2740905\t valid mse: 1.390755853585617\n",
      "Epoch 9 train mse: 1.24063253\t valid mse: 1.3868206583080709\n",
      "Epoch 10 train mse: 1.271526\t valid mse: 1.387643232578708\n",
      "Epoch 11 train mse: 1.2382971\t valid mse: 1.429942577332647\n",
      "Epoch 12 train mse: 1.257513\t valid mse: 1.39043292289150420175\n",
      "Epoch 13 train mse: 1.2672037\t valid mse: 1.3915434943253315\n",
      "Epoch 14 train mse: 1.2558796\t valid mse: 1.3845799422975797343 14 train mse: 1.2563964\n",
      "Epoch 15 train mse: 1.2648051\t valid mse: 1.3851705486087627\n",
      "Epoch 16 train mse: 1.2739961\t valid mse: 1.384548304056349\n",
      "Epoch 17 train mse: 1.2389148\t valid mse: 1.389008611485649mse: 1.2503473\n",
      "Epoch 18 train mse: 1.2550786\t valid mse: 1.385844388472105mse: 1.2673998\n",
      "Epoch 19 train mse: 1.2639418\t valid mse: 1.388909864339539\n",
      "Epoch 20 train mse: 1.2488897\t valid mse: 1.3872067385567415\n",
      "Epoch 21 train mse: 1.2801647\t valid mse: 1.38509061162813 mse: 1.2655816\n",
      "Epoch 22 train mse: 1.2475302\t valid mse: 1.3880296170158661 1.2436868\n",
      "Epoch 23 train mse: 1.244682\t valid mse: 1.3871953338398575\n",
      "Epoch 24 train mse: 1.2695222\t valid mse: 1.3898786331794044\n",
      "Epoch 25 train mse: 1.2763315\t valid mse: 1.3864542908205748in mse: 1.2838122 25 train mse: 1.2696869 25 train mse: 1.2745627\n",
      "Epoch 26 train mse: 1.221151\t valid mse: 1.3881315318265637in mse: 1.27648626 train mse: 1.2558099 26 train mse: 1.2201767\n",
      "Epoch 27 train mse: 1.2641841\t valid mse: 1.3839644256206374\n",
      "Epoch 28 train mse: 1.2521495\t valid mse: 1.3850559316447868\n",
      "Epoch 29 train mse: 1.2846946\t valid mse: 1.3887673283763449\n",
      "Epoch 30 train mse: 1.2449164\t valid mse: 1.383966216326693mse: 1.2348956\n",
      "Epoch 31 train mse: 1.2701483\t valid mse: 1.3969313526770708\n",
      "Epoch 32 train mse: 1.2662897\t valid mse: 1.383253257278645\n",
      "Epoch 33 train mse: 1.2523968\t valid mse: 1.388817558518471\n",
      "Epoch 34 train mse: 1.2419415\t valid mse: 1.3842547379157542\n",
      "Epoch 35 train mse: 1.2341003\t valid mse: 1.3854857128327647\n",
      "Epoch 36 train mse: 1.294118\t valid mse: 1.3890922961412322\n",
      "Epoch 37 train mse: 1.2658242\t valid mse: 1.3841886922800206\n",
      "Epoch 38 train mse: 1.2538962\t valid mse: 1.3930355731389008\n",
      "Epoch 39 train mse: 1.2703968\t valid mse: 1.3872964828929284\n",
      "Epoch 40 train mse: 1.2482989\t valid mse: 1.3857496914481606318\n",
      "Epoch 41 train mse: 1.2788539\t valid mse: 1.3838009594852185\n",
      "Epoch 42 train mse: 1.2542492\t valid mse: 1.383680513385348mse: 1.2910005\n",
      "Epoch 43 train mse: 1.2440857\t valid mse: 1.3847089614853894\n",
      "Epoch 44 train mse: 1.2661928\t valid mse: 1.38664285373604671.264579\n",
      "Epoch 45 train mse: 1.2565554\t valid mse: 1.3941521537167285 mse: 1.2545409\n",
      "Epoch 46 train mse: 1.2645795\t valid mse: 1.3945658842506476\n",
      "Epoch 47 train mse: 1.2667615\t valid mse: 1.3837593492102356843\n",
      "Epoch 48 train mse: 1.2741866\t valid mse: 1.38633010857718061.2723308 48 train mse: 1.2758322\n",
      "Epoch 49 train mse: 1.2928976\t valid mse: 1.387527886933317\n",
      "Epoch 50 train mse: 1.2530203\t valid mse: 1.3842395317257132in mse: 1.2528344train mse: 1.2554272\n",
      "Epoch 51 train mse: 1.252142\t valid mse: 1.3848110095726722\n",
      "Epoch 52 train mse: 1.2867535\t valid mse: 1.38351743653349611.3215654 train mse: 1.2948154 train mse: 1.2819967 52 train mse: 1.2824805\n",
      "Epoch 53 train mse: 1.2489892\t valid mse: 1.3850810352262897\n",
      "Epoch 54 train mse: 1.2576203\t valid mse: 1.38363318583219\n",
      "Epoch 55 train mse: 1.2534529\t valid mse: 1.384718125227471 mse: 1.2546391\n",
      "Epoch 56 train mse: 1.2399967\t valid mse: 1.3842538301381537se: 1.2298541\n",
      "Epoch 57 train mse: 1.26735541.2505001\t valid mse: 1.3835373698338411\n",
      "Epoch 58 train mse: 1.2597497\t valid mse: 1.3860338400573877\n",
      "Epoch 59 train mse: 1.2789907\t valid mse: 1.3832260816750666 1.2952754 59 train mse: 1.2910831\n",
      "Epoch 60 train mse: 1.2791712\t valid mse: 1.3881611776431912in mse: 1.2896944\n",
      "Epoch 61 train mse: 1.2320113\t valid mse: 1.3935826395307855\n",
      "Epoch 62 train mse: 1.2502136\t valid mse: 1.3839384620390442\n",
      "Epoch 63 train mse: 1.2577565\t valid mse: 1.3837976547464386\n",
      "Epoch 64 train mse: 1.2492235\t valid mse: 1.3890111588812852\n",
      "Epoch 65 train mse: 1.2369795\t valid mse: 1.3866946441422164train mse: 1.2411267\n",
      "Epoch 66 train mse: 1.2305291\t valid mse: 1.38921935878703186train mse: 1.2320377\n",
      "Epoch 67 train mse: 1.2491668\t valid mse: 1.3834216362878808\n",
      "Epoch 68 train mse: 1.2666503\t valid mse: 1.382953852883798\n",
      "Epoch 69 train mse: 1.2794288\t valid mse: 1.3829717049446162\n",
      "Epoch 70 train mse: 1.2931952\t valid mse: 1.382925034038844168 70 train mse: 1.2941053\n",
      "Epoch 71 train mse: 1.2521445\t valid mse: 1.3834504789166835\n",
      "Epoch 72 train mse: 1.231355\t valid mse: 1.4094473510641357\n",
      "Epoch 73 train mse: 1.2613351\t valid mse: 1.38407411296659192567302\n",
      "Epoch 74 train mse: 1.2514775\t valid mse: 1.383887206352462n mse: 1.2635394 74 train mse: 1.2480332\n",
      "Epoch 75 train mse: 1.2969402\t valid mse: 1.384273380924092e: 1.3005776\n",
      "Epoch 76 train mse: 1.2423642\t valid mse: 1.387540511577644ain mse: 1.2370253\n",
      "Epoch 77 train mse: 1.2583815\t valid mse: 1.3887233524987468\n",
      "Epoch 78 train mse: 1.255901\t valid mse: 1.388346374912681se: 1.2686057\n",
      "Epoch 79 train mse: 1.2383336\t valid mse: 1.38583841269677\n",
      "Epoch 80 train mse: 1.2493558\t valid mse: 1.383938405508763658\n",
      "Epoch 81 train mse: 1.2406927\t valid mse: 1.3833391441460576\n",
      "Epoch 82 train mse: 1.2914122\t valid mse: 1.3836440356901218\n",
      "Epoch 83 train mse: 1.2872248\t valid mse: 1.3833065728066016\n",
      "Epoch 84 train mse: 1.2555534\t valid mse: 1.3841582146988958\n",
      "Epoch 85 train mse: 1.2584519\t valid mse: 1.386684677818374\n",
      "Epoch 86 train mse: 1.231958\t valid mse: 1.3974679206506901\n",
      "Epoch 87 train mse: 1.264705\t valid mse: 1.3829417004560194\n",
      "Epoch 88 train mse: 1.2514918\t valid mse: 1.3865408386258984 mse: 1.227617 88 train mse: 1.2519188\n",
      "Epoch 89 train mse: 1.24124427\t valid mse: 1.387789796954703\n",
      "Epoch 90 train mse: 1.26729634 90 train mse: 1.2488915train mse: 1.3448378train mse: 1.2670786\t valid mse: 1.3852302396910792\n",
      "Epoch 91 train mse: 1.2674948\t valid mse: 1.3874894547704035n mse: 1.2394092 train mse: 1.2668988\n",
      "Epoch 92 train mse: 1.2535266\t valid mse: 1.386037886371899495\n",
      "Epoch 93 train mse: 1.2283028\t valid mse: 1.3832665607522991\n",
      "Epoch 94 train mse: 1.2783827\t valid mse: 1.38672171739827691.2564486 train mse: 1.2275169 94 train mse: 1.2327144 94 train mse: 1.2690073\n",
      "Epoch 95 train mse: 1.2766967\t valid mse: 1.3876546202672588\n",
      "Epoch 96 train mse: 1.267292\t valid mse: 1.3837514891010052\n",
      "Epoch 97 train mse: 1.2772207\t valid mse: 1.3856149295295146\n",
      "Epoch 98 train mse: 1.277331\t valid mse: 1.3859311333874969669\n",
      "Epoch 99 train mse: 1.2589511\t valid mse: 1.388508638583074\n"
     ]
    }
   ],
   "source": [
    "# fit 中做的事\n",
    "# 1. batch 遍历数据集 metric\n",
    "#   1.1 自动求导\n",
    "# 2. epoch 结束 验证集 metric\n",
    "\n",
    "# 准备工作\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(x_train_scaled) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "def random_batch(x,y,batch_size=32):\n",
    "    idx = np.random.randint(0,len(x),size=batch_size)\n",
    "    return x[idx],y[idx]\n",
    "\n",
    "# 搭建模型\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation='relu',input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "    \n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch,y_batch = random_batch(x_train_scaled,y_train,batch_size)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            y_pred = model(x_batch)\n",
    "            loss = tf.reduce_mean(keras.losses.mean_squared_error(y_batch,y_pred))\n",
    "            metric(y_batch,y_pred)\n",
    "        \n",
    "        grads = tape.gradient(loss,model.variables)\n",
    "        grads_and_vars = zip(grads,model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print('\\rEpoch',epoch,'train mse:',metric.result().numpy(),end='')\n",
    "    \n",
    "    y_valid_pred = model(x_valid_scaled)\n",
    "    valid_loss = tf.reduce_mean(keras.losses.mean_squared_error(y_valid_pred,y_valid))\n",
    "    print('\\t','valid mse:',valid_loss.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf20]",
   "language": "python",
   "name": "conda-env-tf20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
